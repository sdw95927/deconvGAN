{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate deconv GAN (wo GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.io\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he NLST\n",
    "he_nlst_folder = \"../data/he/\"\n",
    "he_nlst = [_ for _ in os.listdir(he_nlst_folder) if _.endswith(\".png\")]\n",
    "\n",
    "# he MDACC\n",
    "he_mdacc_folder = \"../data/HE_unlabeled/\"\n",
    "he_mdacc = [_ for _ in os.listdir(he_mdacc_folder) if _.endswith(\".png\")]\n",
    "\n",
    "# ihc (ori)\n",
    "ihc_ori = []\n",
    "for folder in [\"CD8\", \"CD3\", \"CD68\", \"PD-L1\"]:\n",
    "    ihc_ori.extend([os.path.join(\"../data\", folder, \"ori\", _) for _ in os.listdir(os.path.join(\"../data\", folder, \"ori\"))\n",
    "                   if _.endswith(\".png\")])\n",
    "np.random.seed(1243)\n",
    "ihc_ori = np.random.choice(ihc_ori, len(he_nlst), replace=False)\n",
    "\n",
    "# ihc (h channel)\n",
    "ihc_h_folder = \"../data/IHC_H_channel/\"\n",
    "ihc_h = [_ for _ in os.listdir(ihc_h_folder) if _.endswith(\".png\")]\n",
    "\n",
    "# Create image dict\n",
    "he_nlst.sort()\n",
    "he_mdacc.sort()\n",
    "ihc_ori.sort()\n",
    "ihc_h.sort()\n",
    "\n",
    "image_dict = dict()\n",
    "slides_he = []\n",
    "slides_ihc = []\n",
    "for index in he_nlst:\n",
    "    _dict = dict()\n",
    "    _dict['image'] = skimage.io.imread(os.path.join(he_nlst_folder, index))\n",
    "    _dict['target'] = None\n",
    "    _dict['image_path'] = os.path.join(he_nlst_folder, index)\n",
    "    if index[0] == \"N\":\n",
    "        _dict['magnitude'] = 20\n",
    "    else:\n",
    "        _dict['magnitude'] = 40\n",
    "    _dict['type'] = \"he\"\n",
    "    image_dict[index] = _dict\n",
    "    slides_he.append(index.split(\"_\")[0])\n",
    "'''\n",
    "for index in he_mdacc:\n",
    "    _dict = dict()\n",
    "    _dict['image'] = skimage.io.imread(os.path.join(he_mdacc_folder, index))\n",
    "    _dict['target'] = None\n",
    "    _dict['image_path'] = os.path.join(he_mdacc_folder, index)\n",
    "    _dict['magnitude'] = 20\n",
    "    _dict['type'] = \"he\"\n",
    "    image_dict[index] = _dict\n",
    "    slides_he.append(index.split(\"_\")[0])\n",
    "'''\n",
    "for index in ihc_ori:\n",
    "    _dict = dict()\n",
    "    _dict['image'] = skimage.io.imread(index)\n",
    "    _dict['target'] = None\n",
    "    _dict['image_path'] = index\n",
    "    _dict['magnitude'] = 20\n",
    "    _dict['type'] = \"ihc\"\n",
    "    image_dict[index] = _dict\n",
    "    slides_ihc.append(index.split(\"/\")[-1].split(\"_\")[0])\n",
    "for index in ihc_h:\n",
    "    _dict = dict()\n",
    "    _dict['image'] = skimage.io.imread(os.path.join(ihc_h_folder, index))\n",
    "    _dict['target'] = None\n",
    "    _dict['image_path'] = os.path.join(ihc_h_folder, index)\n",
    "    _dict['magnitude'] = 20\n",
    "    _dict['type'] = \"ihc\"\n",
    "    image_dict[index] = _dict\n",
    "    slides_ihc.append(index.split(\"_\")[0])\n",
    "\n",
    "slides_he = list(set(slides_he))\n",
    "slides_ihc = list(set(slides_ihc))\n",
    "slides_he.sort()\n",
    "slides_ihc.sort()\n",
    "\n",
    "# Split train, val, test\n",
    "he_indexes = []\n",
    "he_indexes.extend(he_nlst)\n",
    "'''he_indexes.extend(he_mdacc)'''\n",
    "np.random.seed(81020)\n",
    "slides_he_train = np.random.choice(slides_he, int(len(slides_he)*0.85), replace=False)\n",
    "slides_he_rest = [_ for _ in slides_he if _ not in slides_he_train]\n",
    "np.random.seed(81020)\n",
    "slides_he_val = np.random.choice(slides_he_rest, int(len(slides_he_rest)*0.5), replace=False)\n",
    "slides_he_test = [_ for _ in slides_he_rest if _ not in slides_he_val]\n",
    "he_indexes_train = [_ for _ in he_indexes if _.split(\"_\")[0] in slides_he_train]\n",
    "he_indexes_val = [_ for _ in he_indexes if _.split(\"_\")[0] in slides_he_val]\n",
    "he_indexes_test = [_ for _ in he_indexes if _.split(\"_\")[0] in slides_he_test]\n",
    "np.random.seed(81020)\n",
    "slides_ihc_train = np.random.choice(slides_ihc, int(len(slides_ihc)*0.85), replace=False)\n",
    "slides_ihc_rest = [_ for _ in slides_ihc if _ not in slides_ihc_train]\n",
    "np.random.seed(81020)\n",
    "slides_ihc_val = np.random.choice(slides_ihc_rest, int(len(slides_ihc_rest)*0.5), replace=False)\n",
    "slides_ihc_test = [_ for _ in slides_ihc_rest if _ not in slides_ihc_val]\n",
    "ihc_ori_indexes_train = [_ for _ in ihc_ori if _.split(\"/\")[-1].split(\"_\")[0] in slides_ihc_train]\n",
    "ihc_ori_indexes_val = [_ for _ in ihc_ori if _.split(\"/\")[-1].split(\"_\")[0] in slides_ihc_val]\n",
    "ihc_ori_indexes_test = [_ for _ in ihc_ori if _.split(\"/\")[-1].split(\"_\")[0] in slides_ihc_test]\n",
    "ihc_h_indexes_train = [_ for _ in ihc_h if _.split(\"_\")[0] in slides_ihc_train]\n",
    "ihc_h_indexes_val = [_ for _ in ihc_h if _.split(\"_\")[0] in slides_ihc_val]\n",
    "ihc_h_indexes_test = [_ for _ in ihc_h if _.split(\"_\")[0] in slides_ihc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10878_2_10.png', '10878_2_8.png', '10878_2_9.png', '11460_1_10.png', '11460_1_2.png', '11460_1_3.png', '11460_1_4.png', '11460_1_5.png', '11460_1_6.png', '11460_1_7.png', '11460_1_8.png', '11460_1_9.png', '11460_2_1.png', '11460_2_10.png', '11460_2_2.png', '11460_2_3.png', '11460_2_4.png', '11460_2_5.png', '11460_2_6.png', '11460_2_7.png', '11460_2_8.png', '11460_2_9.png', '9529_1_1.png', '9529_1_2.png', '9529_1_3.png', '9529_1_4.png', 'NLSI0000078_2_10.png', 'NLSI0000078_2_6.png', 'NLSI0000078_2_7.png', 'NLSI0000078_2_8.png', 'NLSI0000078_2_9.png', 'NLSI0000165_1_1.png']\n"
     ]
    }
   ],
   "source": [
    "print(he_indexes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# he_indexes_train: 368\n",
      "# he_indexes_val: 43\n",
      "# he_indexes_test: 32\n",
      "\n",
      "# ihc_ori_indexes_train: 360\n",
      "# ihc_ori_indexes_val: 43\n",
      "# ihc_ori_indexes_test: 40\n",
      "\n",
      "# ihc_indexes_train: 500\n",
      "# ihc_indexes_val: 40\n",
      "# ihc_indexes_test: 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# he_indexes_train: {}\\n# he_indexes_val: {}\\n# he_indexes_test: {}\\n'.format(len(he_indexes_train), \n",
    "                                                                                     len(he_indexes_val), \n",
    "                                                                                     len(he_indexes_test)))\n",
    "print('# ihc_ori_indexes_train: {}\\n# ihc_ori_indexes_val: {}\\n# ihc_ori_indexes_test: {}\\n'.format(len(ihc_ori_indexes_train), \n",
    "                                                                                     len(ihc_ori_indexes_val), \n",
    "                                                                                     len(ihc_ori_indexes_test)))\n",
    "print('# ihc_indexes_train: {}\\n# ihc_indexes_val: {}\\n# ihc_indexes_test: {}\\n'.format(len(ihc_h_indexes_train), \n",
    "                                                                                     len(ihc_h_indexes_val), \n",
    "                                                                                     len(ihc_h_indexes_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stain_OD_norm\n",
    "stain_OD = [[0.644211, 0.716556, 0.266844],  # Hematoxylin\n",
    "            [0.092789, 0.964111, 0.283111],  # Eosin\n",
    "            [0.268000, 0.570000, 0.776000],  # DAB\n",
    "            [0.000000, 0.70711, 0.70711],  # Bg-r\n",
    "            [0.70711, 0.000000, 0.70711],  # Bg-g\n",
    "            [0.70711, 0.70711, 0.000000],  # Bg-b\n",
    "           ]\n",
    "stain_OD_norm = []\n",
    "for r in stain_OD:\n",
    "    stain_OD_norm.append(r/np.linalg.norm(r))\n",
    "stain_OD_norm = torch.tensor(np.asarray(stain_OD_norm))\n",
    "IMAGE_SHAPE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Create and check data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Wedge, Polygon, Rectangle\n",
    "import numpy as np\n",
    "import math\n",
    "import skimage\n",
    "import skimage.transform\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "from utils_image import rgba2rgb, split_masks, Crop, binary_mask_to_polygon\n",
    "from segmentation_functions import channel_deconvolution\n",
    "\n",
    "def normalize(image, inverse=False):\n",
    "    if not inverse:\n",
    "        image = image/255.\n",
    "    else:\n",
    "        image = np.clip(image*255, 0, 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def augmentor(image, label=None, stain=None):\n",
    "    \"\"\"Do image shape and color augmentation.\n",
    "    \n",
    "    Args:\n",
    "        image: [h, w, c], float\n",
    "    \"\"\"\n",
    "    n_channels = image.shape[2]\n",
    "    \n",
    "    if stain is not None:\n",
    "        stain = stain/255.\n",
    "    \n",
    "    # Shape augmentation\n",
    "    if np.random.uniform(0, 1) < 0.8:\n",
    "        # Projective transform\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        aspect_ratio = np.random.uniform(0.9, 1.1)\n",
    "        rotation = np.random.uniform(-0.1, 0.1)\n",
    "        translationX = np.random.uniform(-10, 10)\n",
    "        translationY = np.random.uniform(-10, 10)\n",
    "        g = np.random.uniform(-0.001, 0.001)\n",
    "        h = np.random.uniform(-0.001, 0.001)\n",
    "\n",
    "        matrix = np.array([[math.cos(rotation) * scale * aspect_ratio, -math.sin(rotation), translationX],\n",
    "                          [math.sin(rotation), math.cos(rotation) * scale / aspect_ratio, translationY],\n",
    "                          [g, h, 1]])\n",
    "        tform = skimage.transform.ProjectiveTransform(matrix=matrix)\n",
    "        image_aug = np.zeros_like(image, dtype=np.float)\n",
    "        for ch in range(n_channels):\n",
    "            image_aug[..., ch] = skimage.transform.warp(image[..., ch], tform, preserve_range=True)\n",
    "        \n",
    "        image = image_aug\n",
    "        \n",
    "        if label is not None:\n",
    "            label_aug = np.zeros_like(label, dtype=np.int)\n",
    "            label_aug = skimage.transform.warp(label, tform, preserve_range=True, order=0)\n",
    "            label = label_aug\n",
    "            \n",
    "        if stain is not None:\n",
    "            stain_aug = np.zeros_like(stain, dtype=np.float)\n",
    "            for ch in range(n_channels):\n",
    "                stain_aug[..., ch] = skimage.transform.warp(stain[..., ch], tform, preserve_range=True)\n",
    "            stain = stain_aug\n",
    "            \n",
    "    if np.random.uniform(0, 1) < 0.5:\n",
    "        # Do 50% vertical flipping\n",
    "        image = image[::-1, :, :]\n",
    "        \n",
    "        if label is not None:\n",
    "            label = label[::-1, :]\n",
    "            \n",
    "        if stain is not None:\n",
    "            stain = stain[::-1, :]\n",
    "    if np.random.uniform(0, 1) < 0.5:\n",
    "        # Do 50% horizontal flipping\n",
    "        image = image[:, ::-1, :]\n",
    "        \n",
    "        if label is not None:\n",
    "            label = label[:, ::-1]\n",
    "            \n",
    "        if stain is not None:\n",
    "            stain = stain[:, ::-1]\n",
    "\n",
    "    # Color augmentation\n",
    "    # 1) add a global shifting for all channels\n",
    "    image = image + np.random.randn(1)[0] * 0.01\n",
    "\n",
    "    # 2) add a shifting & variance for each channel\n",
    "    for ch in range(n_channels):\n",
    "        image[:, :, ch] = image[:, :, ch] * np.clip(np.random.randn(1)[0] * 0.01 + 1, 0.95, 1.05) + np.random.randn(1)[0] * 0.01\n",
    "        \n",
    "    return image, label\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    __initialized = False\n",
    "    def __init__(self, indexes_A, indexes_B, image_dict,\n",
    "                 augmentation=False, crop_size=256, crop_position=\"random\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            indexes: index used for image_dict\n",
    "            indexes_A: IHC + HE\n",
    "            indexes_B: IHC H channel\n",
    "        \"\"\"\n",
    "        self.indexes_A = indexes_A\n",
    "        self.indexes_B = indexes_B\n",
    "        self.length_B = len(indexes_B)\n",
    "        self.image_dict = image_dict\n",
    "        self.augmentation = augmentation\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_position = crop_position\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of samples\"\"\"\n",
    "        return len(self.indexes_A)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\n",
    "        \n",
    "        Returns:\n",
    "            idx: indexes of samples (long)\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        data_index_A = self.indexes_A[index]\n",
    "        np.random.seed()\n",
    "        idx_B = np.random.choice(np.arange(self.length_B))\n",
    "        data_index_B = self.indexes_B[idx_B]\n",
    "        \n",
    "        # Generate data\n",
    "        image_A, _ = self.__data_generation(data_index_A, index)\n",
    "        image_B, _ = self.__data_generation(data_index_B, idx_B, h_channel=True)\n",
    "        \n",
    "        '''\n",
    "        data = dict()\n",
    "        data['A'] = image_A\n",
    "        data['B'] = image_B\n",
    "        data['A_paths'] = self.image_dict[data_index_A]['image_path']\n",
    "        data['B_paths'] = self.image_dict[data_index_B]['image_path']\n",
    "        data['target_B'] = target_B\n",
    "        data['stain_A'] = stain_A\n",
    "        '''\n",
    "\n",
    "        return image_A, image_B, self.image_dict[data_index_A]['type']\n",
    "    \n",
    "    def __data_generation(self, index, idx=0, h_channel=False):\n",
    "        \"\"\"Generates image containing batch_size samples.\n",
    "        \n",
    "        Args:\n",
    "            h_channel: if True, return deconvoluted single channel image\n",
    "        \n",
    "        Returns:\n",
    "            image: [b, ch, h, w]\n",
    "        \"\"\"\n",
    "        image = rgba2rgb(self.image_dict[index]['image'])\n",
    "        target = self.image_dict[index]['target']\n",
    "        image_path = self.image_dict[index]['image_path']\n",
    "        \n",
    "        # Process target\n",
    "        if target is not None:\n",
    "            target = normal_cell_to_stroma(rgba2rgb(target))\n",
    "            objects = split_masks(target, val_to_label=self.val_to_label, dtype='float')\n",
    "            target = np.transpose(np.array([x['mask'] for x in objects]), (1, 2, 0))\n",
    "            labels = [x['label'] for x in objects]\n",
    "        \n",
    "        # Augmentation\n",
    "        if h_channel:\n",
    "            _, image, _, _ = channel_deconvolution(image, \"HDB\", to_normalize=False)\n",
    "            image = np.clip(image, 0, None)\n",
    "            image = image[..., np.newaxis]\n",
    "        elif self.augmentation:\n",
    "            image, target = augmentor(image/255., target)\n",
    "        else:\n",
    "            image = image/255.\n",
    "            \n",
    "        # Resize\n",
    "        if self.image_dict[index]['magnitude'] == 20:\n",
    "            image = skimage.transform.rescale(image, 2, preserve_range=True, multichannel=True, order=1)\n",
    "            if target is not None:\n",
    "                target = skimage.transform.rescale(target, 2, preserve_range=True, multichannel=True, order=0)\n",
    "                \n",
    "        # Random crop\n",
    "        image, target = Crop(size=(self.crop_size, self.crop_size), pos=self.crop_position)([image, target])\n",
    "        \n",
    "        # Filter small objects & create target for MaskRCNN\n",
    "        if target is not None:\n",
    "            non_zeros = [(target[..., i], labels[i]) for i in range(len(labels)) if np.sum(target[..., i]) > 10]\n",
    "            if len(non_zeros):\n",
    "                target, labels = zip(*non_zeros)\n",
    "            else:\n",
    "                target = [np.ones((self.crop_size, self.crop_size))]\n",
    "                labels = [0]\n",
    "            target = objects_to_tensor_targets(target, labels, idx)\n",
    "        \n",
    "        image = torch.tensor(np.transpose(image, (2, 0, 1)).astype(float))\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def display(self, indices=None):\n",
    "        if indices is None:\n",
    "            indices = range(len(self))\n",
    "        elif isinstance(indices, int):\n",
    "            indices = np.random.choice(len(self), indices)\n",
    "        for i in indices:\n",
    "            data = self[i]\n",
    "            image = data['B']\n",
    "            targets = data['target_B']\n",
    "            image = image.permute(1, 2, 0).numpy()\n",
    "            if targets is not None:\n",
    "                bboxes = targets['boxes'].numpy()\n",
    "                labels = targets['labels'].numpy()\n",
    "                masks = targets['masks'].numpy()\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 2, figsize=(6 * 2, 6))\n",
    "            ax[0].imshow(np.array(np.clip(image * 255, 0, 255), dtype=np.uint8))\n",
    "            ax[1].imshow(np.array(np.clip(image * 255, 0, 255), dtype=np.uint8))\n",
    "            if targets is not None:\n",
    "                color = self.label_to_val\n",
    "                for i, (mask, bbox, label) in enumerate(zip(masks, bboxes, labels)):\n",
    "                    c = tuple([1.0*_/255 for _ in color[label]]) if label else (0, 0, 0)\n",
    "                    polygon = binary_mask_to_polygon(mask)\n",
    "                    for verts in polygon:\n",
    "                        p = Polygon(np.array(verts[:, ::-1]), facecolor=\"none\", edgecolor=c)\n",
    "                        ax[1].add_patch(p)\n",
    "                    y1, x1, y2, x2 = bbox\n",
    "                    b = Rectangle((y1, x1), (y2-y1), (x2-x1), linewidth=2,\n",
    "                                  alpha=0.5, linestyle=\"solid\", edgecolor=c, facecolor=\"none\")\n",
    "                    ax[1].add_patch(b)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "# def collate_fn(batch):\n",
    "#     return list(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "######## Activations ########\n",
    "\n",
    "class MishFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x = ctx.saved_variables[0]\n",
    "        sigmoid = torch.sigmoid(x)\n",
    "        tanh_sp = torch.tanh(F.softplus(x)) \n",
    "        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return MishFunction.apply(x)\n",
    "    \n",
    "######## Blocks ########\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, activation=nn.PReLU()):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.activation = activation\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.activation(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        return self.activation(x + residual)\n",
    "    \n",
    "######## Encoder ########\n",
    "    \n",
    "class ODEncoder(nn.Module):\n",
    "    def __init__(self, activation=nn.PReLU()):\n",
    "        '''\n",
    "        Args:\n",
    "            activation: nn.PReLU(), nn.ReLU(), nn.LeakyReLU(0.2), Mish()\n",
    "        '''\n",
    "        super(ODEncoder, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            activation\n",
    "        )\n",
    "        self.block2 = ResidualBlock(64, activation)\n",
    "        self.block3 = ResidualBlock(64, activation)\n",
    "        self.block4 = ResidualBlock(64, activation)\n",
    "        self.block5 = ResidualBlock(64, activation)\n",
    "        self.block6 = ResidualBlock(64, activation)\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 6, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(6)\n",
    "        )\n",
    "        \n",
    "        self.block8 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation,\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation,\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation,\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation,\n",
    "            nn.AdaptiveMaxPool2d((1, 1))\n",
    "        )\n",
    "        self.block9 = nn.Sequential(\n",
    "            nn.Linear(32, 3*3),\n",
    "            activation\n",
    "        )\n",
    "        self.block10 = nn.Sequential(\n",
    "            nn.Linear(32, 2), \n",
    "            activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        block4 = self.block4(block3)\n",
    "        block5 = self.block5(block4)\n",
    "        block6 = self.block6(block5)\n",
    "        block7 = self.block7(block1 + block6)\n",
    "        \n",
    "        block8 = self.block8(block1)\n",
    "        block8 = block8.view(-1, 32)\n",
    "        block9 = self.block9(block8)\n",
    "        block9 = block9.view(-1, 3, 3)\n",
    "        block9 = torch.sqrt(F.softmax(block9, -1))\n",
    "        block10 = self.block10(block8)\n",
    "\n",
    "        return nn.ReLU()(block7), block9, block10\n",
    "    \n",
    "def reconstruct(ODs, stain_OD_norm, device):\n",
    "    '''Reconstruct image from different stains\n",
    "    \n",
    "    Args:\n",
    "        ODs: [B, n_stains, H, W]\n",
    "        stain_OD_norm: [n_stains, 3 (R, G, B)] or [B, n_stains, 3 (R, G, B)]\n",
    "    '''\n",
    "    if not isinstance(ODs, torch.Tensor):\n",
    "        ODs = torch.tensor(ODs).float()\n",
    "    if not isinstance(stain_OD_norm, torch.Tensor):\n",
    "        stain_OD_norm = torch.tensor(stain_OD_norm)\n",
    "    if len(ODs.size()) != 4:\n",
    "        raise Exception(\"ODs should be of shape [B, n_stains, H, W]\")\n",
    "    if len(stain_OD_norm.size()) == 2:\n",
    "        # If the batch of images have the same stain_OD_norm\n",
    "        ODs = ODs.permute(0, 2, 3, 1)\n",
    "        ODs = ODs.to(device)\n",
    "        stain_OD_norm = stain_OD_norm.to(device)\n",
    "        stain_OD_norm = stain_OD_norm.float()\n",
    "        reconstructed = torch.matmul(ODs, stain_OD_norm)\n",
    "        reconstructed = torch.exp(torch.neg(reconstructed.permute(0, 3, 1, 2)))\n",
    "    elif len(stain_OD_norm.size()) == 3:\n",
    "        # If the batch of images have different stain_OD_norms\n",
    "        size = ODs.size()\n",
    "        ODs = ODs.view(size[0], size[1], size[2] * size[3])\n",
    "        ODs = ODs.permute(0, 2, 1)\n",
    "        ODs = ODs.to(device)\n",
    "        stain_OD_norm = stain_OD_norm.to(device)\n",
    "        stain_OD_norm = stain_OD_norm.float()\n",
    "        reconstructed = torch.bmm(ODs, stain_OD_norm)  #[B, H*W, 3]\n",
    "        reconstructed = torch.exp(torch.neg(reconstructed.permute(0, 2, 1)))\n",
    "        reconstructed = reconstructed.view(size[0], 3, size[2], size[3])\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg16\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "class ReconstructionLoss(nn.Module):\n",
    "    def __init__(self, weight=None):\n",
    "        super(ReconstructionLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.mean=[0.485, 0.456, 0.406]\n",
    "        self.std=[0.229, 0.224, 0.225]\n",
    "        if weight is None:\n",
    "            self.weight_image_loss = 10\n",
    "            self.weight_perceptual_loss = 1\n",
    "            self.weight_bg_penalty = 0.1\n",
    "            self.weight_stain_penalty = 0.1\n",
    "            self.weight_h_sparsity = 0.1\n",
    "            self.weight_e_penalty = 0.1\n",
    "            self.weight_cov_penalty = 1\n",
    "        else:\n",
    "            self.weight_image_loss = weight[0]\n",
    "            self.weight_perceptual_loss = weight[1]\n",
    "            self.weight_bg_penalty = weight[2]\n",
    "            self.weight_stain_penalty = weight[3]\n",
    "            self.weight_h_sparsity = weight[4]\n",
    "            if len(weight) > 5:\n",
    "                self.weight_e_penalty = weight[5]\n",
    "            else:\n",
    "                self.weight_e_penalty = 0\n",
    "            if len(weight) > 6:\n",
    "                self.weight_cov_penalty = weight[6]\n",
    "            else:\n",
    "                self.weight_cov_penalty = 0\n",
    "        \n",
    "    def forward(self, recon_images_exact, recon_images_valid, target_images, ODs, stain_types):\n",
    "        '''\n",
    "        Args:\n",
    "            recon_images: in shape [b, c, h, w]. exact: use all channels; valid: use valid channels\n",
    "        '''\n",
    "        # Image Loss\n",
    "        image_loss = self.mse_loss(recon_images_exact, target_images)\n",
    "        \n",
    "        # Perceptual Loss\n",
    "        recon_images_n = recon_images_valid.clone()\n",
    "        target_images_n = target_images.clone()\n",
    "        for ch in range(3):\n",
    "            recon_images_n[:, ch, ...] = (recon_images_valid[:, ch, ...] - self.mean[ch])/self.std[ch]\n",
    "            target_images_n[:, ch, ...] = (target_images[:, ch, ...] - self.mean[ch])/self.std[ch]\n",
    "        perceptual_loss = self.mse_loss(self.loss_network(recon_images_n), \n",
    "                                        self.loss_network(target_images_n))\n",
    "        # Background penalty\n",
    "        for i, stain_type in enumerate(stain_types):\n",
    "            if i != 0:\n",
    "                if stain_type == \"he\":\n",
    "                    bg_penalty += torch.mean(ODs[i, [2, 3, 4, 5], ...])\n",
    "                elif stain_type == \"ihc\":\n",
    "                    bg_penalty += torch.mean(ODs[i, [1, 3, 4, 5], ...])\n",
    "            else:\n",
    "                if stain_type == \"he\":\n",
    "                    bg_penalty = torch.mean(ODs[i, [2, 3, 4, 5], ...])\n",
    "                elif stain_type == \"ihc\":\n",
    "                    bg_penalty = torch.mean(ODs[i, [1, 3, 4, 5], ...])\n",
    "        bg_penalty = torch.div(bg_penalty, i + 1)\n",
    "                    \n",
    "        # Stain penalty\n",
    "        for i, stain_type in enumerate(stain_types):\n",
    "            if i != 0:\n",
    "                if stain_type == \"he\":\n",
    "                    stain_penalty += torch.mean(ODs[i, [0, 1], ...])\n",
    "                elif stain_type == \"ihc\":\n",
    "                    stain_penalty += torch.mean(ODs[i, [0, 2], ...])\n",
    "            else:\n",
    "                if stain_type == \"he\":\n",
    "                    stain_penalty = torch.mean(ODs[i, [0, 1], ...])\n",
    "                elif stain_type == \"ihc\":\n",
    "                    stain_penalty = torch.mean(ODs[i, [0, 2], ...])\n",
    "        stain_penalty = torch.div(stain_penalty, i + 1)\n",
    "        \n",
    "        # H sparsity\n",
    "        h_sparsity = torch.sum(ODs[:, 0, ...]).float()/ODs.size()[0]/ODs.size()[2]/ODs.size()[3]\n",
    "        \n",
    "        # E penalty\n",
    "        j = 0\n",
    "        for i, stain_type in enumerate(stain_types):\n",
    "            if j != 0:\n",
    "                if stain_type == \"he\":\n",
    "                    e_penalty += torch.mean(ODs[i, [1], ...])\n",
    "            else:\n",
    "                if stain_type == \"he\":\n",
    "                    e_penalty = torch.mean(ODs[i, [1], ...])\n",
    "                    j += 1\n",
    "        e_penalty = torch.div(e_penalty, i + 1)\n",
    "        \n",
    "        # Covariance penalty\n",
    "        cov_penalty = torch.mean(ODs[:, 0, ...] * ODs[:, 1, ...]) - torch.mean(ODs[:, 0, ...]) * torch.mean(ODs[:, 1, ...])\n",
    "        \n",
    "        self.image_loss = self.weight_image_loss * image_loss\n",
    "        self.perceptual_loss = self.weight_perceptual_loss * perceptual_loss\n",
    "        self.bg_penalty = self.weight_bg_penalty * bg_penalty\n",
    "        self.stain_penalty = self.weight_stain_penalty * stain_penalty\n",
    "        self.h_sparsity = self.weight_h_sparsity * h_sparsity\n",
    "        self.e_penalty = self.weight_e_penalty * e_penalty\n",
    "        self.cov_penalty = self.weight_cov_penalty * cov_penalty\n",
    "        \n",
    "        return self.image_loss + self.perceptual_loss + self.bg_penalty + self.stain_penalty + self.h_sparsity + self.e_penalty \\\n",
    "                 + self.cov_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# self-defined functions\n",
    "from util.image_pool import ImagePool\n",
    "import networks\n",
    "\n",
    "class DeconvGAN():\n",
    "    def __init__(self, is_train=True, device=\"0\", activation=Mish(), weight=[10, 1, 0.1, 0, 0, 0, 0], \n",
    "                lr=0.0002, beta1=0.5, save_dir=\"./models/\", n_epochs=500, n_epochs_decay=100):\n",
    "        self.is_train = is_train\n",
    "        self.device = device\n",
    "        self.save_dir = save_dir  # which folder to save models\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_epochs_decay = n_epochs_decay\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.model_names = ['G', 'D']\n",
    "        else:\n",
    "            self.model_names = ['G']\n",
    "\n",
    "        # define networks \n",
    "        self.netG = ODEncoder(activation=activation)\n",
    "        self.netG = self.netG.to(self.device)\n",
    "\n",
    "        if self.is_train:  # define discriminators\n",
    "            '''    Parameters:\n",
    "            input_nc (int)     -- the number of channels in input images\n",
    "            ndf (int)          -- the number of filters in the first conv layer\n",
    "            netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
    "            n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
    "            norm (str)         -- the type of normalization layers used in the network.\n",
    "            init_type (str)    -- the name of the initialization method.\n",
    "            init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "            gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2'''\n",
    "            self.netD = networks.define_D(input_nc=1, ndf=64, netD=\"basic\", n_layers_D=3,\n",
    "                                          norm=\"instance\", init_type=\"normal\", init_gain=0.02, gpu_ids=[device])\n",
    "            \n",
    "        self.criterionRec = ReconstructionLoss(weight=weight).to(self.device)\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.fake_pool = ImagePool(50)\n",
    "            # define loss functions\n",
    "            self.criterionGAN = networks.GANLoss(\"lsgan\").to(self.device)  # define GAN loss.\n",
    "            # initialize optimizers\n",
    "            self.optimizers = []\n",
    "            self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "            self.schedulers = [networks.get_scheduler(optimizer, lr_policy=\"linear\", \n",
    "                                                      n_epochs=n_epochs, n_epochs_decay=n_epochs_decay) for optimizer in self.optimizers]\n",
    "\n",
    "    def set_input(self, data):\n",
    "        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n",
    "        Parameters:\n",
    "            input (dict): include the data itself and its metadata information.\n",
    "        \"\"\"\n",
    "        self.images = data[0].float().to(self.device)\n",
    "        self.real_hs = data[1].float().to(self.device)\n",
    "        self.stain_types = data[2]\n",
    "\n",
    "    def forward(self, val=False):\n",
    "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
    "        if val:\n",
    "            self.netG.eval()\n",
    "        else:\n",
    "            self.netG.train()\n",
    "        self.ODs, self.stain_OD_norm_preds, self.params_lt = self.netG(self.images)\n",
    "        self.fake_hs = torch.log(self.ODs[:, 0:1, ...] + 1) * self.params_lt[:, 0, None, None, None] + \\\n",
    "                                 self.params_lt[:, 1, None, None, None]\n",
    "        \n",
    "        # Add rgb to ODs\n",
    "        rgb_ODs = torch.stack([torch.tensor([[0, 0.70711, 0.70711], \n",
    "                                             [0.70711, 0, 0.70711], \n",
    "                                             [0.70711, 0.70711, 0]]) for _ in range(self.ODs.size()[0])], 0)\n",
    "        self.stain_OD_norm_preds = torch.cat([self.stain_OD_norm_preds, rgb_ODs.to(self.device)], 1)\n",
    "        \n",
    "        self.recon_images_exact = reconstruct(self.ODs, self.stain_OD_norm_preds, self.device)\n",
    "        self.recon_images_valid = torch.zeros_like(self.recon_images_exact).to(self.device)\n",
    "        for i, stain_type in enumerate(self.stain_types):\n",
    "            if stain_type == \"he\":\n",
    "                self.recon_images_valid[i:i+1, ...] = reconstruct(self.ODs[i:i+1, 0:2, ...], \n",
    "                                                             self.stain_OD_norm_preds[i:i+1, 0:2, ...], self.device)\n",
    "            if stain_type == \"ihc\":\n",
    "                self.recon_images_valid[i:i+1, ...] = reconstruct(self.ODs[i:i+1, [0, 2], ...], \n",
    "                                                             self.stain_OD_norm_preds[i:i+1, [0, 2], ...], self.device)\n",
    "        self.loss_rec = self.criterionRec(self.recon_images_exact, self.recon_images_valid, self.images, self.ODs, self.stain_types)\n",
    "        self.image_loss = self.criterionRec.image_loss\n",
    "        self.perceptual_loss = self.criterionRec.perceptual_loss\n",
    "        self.bg_penalty = self.criterionRec.bg_penalty\n",
    "        self.stain_penalty = self.criterionRec.stain_penalty\n",
    "        self.h_sparsity = self.criterionRec.h_sparsity\n",
    "        self.e_penalty = self.criterionRec.e_penalty\n",
    "        self.cov_penalty = self.criterionRec.cov_penalty\n",
    "\n",
    "    def backward_D_basic(self, netD, real, fake, val=False):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\n",
    "        Parameters:\n",
    "            netD (network)      -- the discriminator D\n",
    "            real (tensor array) -- real images\n",
    "            fake (tensor array) -- images generated by a generator\n",
    "        Return the discriminator loss.\n",
    "        We also call loss_D.backward() to calculate the gradients.\n",
    "        \"\"\"\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss and calculate gradients\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        if not val:\n",
    "            loss_D.backward()\n",
    "        return loss_D\n",
    "\n",
    "    def backward_D(self, val=False):\n",
    "        \"\"\"Calculate GAN loss for discriminator D_A\"\"\"\n",
    "        fake_hs = self.fake_pool.query(self.fake_hs)\n",
    "        self.loss_D = self.backward_D_basic(self.netD, self.real_hs, fake_hs, val=val)\n",
    "\n",
    "    def backward_G(self, val=False):\n",
    "        \"\"\"Calculate the loss for generator G\"\"\"\n",
    "\n",
    "        # GAN loss\n",
    "        self.loss_gan = self.criterionGAN(self.netD(self.fake_hs), True)\n",
    "        # combined loss and calculate gradients\n",
    "        self.loss_G = self.loss_gan + self.loss_rec\n",
    "        \n",
    "        if not val:\n",
    "            self.loss_G.backward()\n",
    "            \n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n",
    "        Parameters:\n",
    "            nets (network list)   -- a list of networks\n",
    "            requires_grad (bool)  -- whether the networks require gradients or not\n",
    "        \"\"\"\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n",
    "        # forward\n",
    "        self.forward()      # compute fake images and reconstruction images.\n",
    "        # G\n",
    "        self.set_requires_grad([self.netD], False)  # Ds require no gradients when optimizing Gs\n",
    "        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero\n",
    "        self.backward_G()             # calculate gradients for G_A and G_B\n",
    "        self.optimizer_G.step()       # update G_A and G_B's weights\n",
    "        # D\n",
    "        self.set_requires_grad([self.netD], True)\n",
    "        self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero\n",
    "        self.backward_D()      # calculate gradients for D_A\n",
    "        self.optimizer_D.step()  # update D_A and D_B's weights\n",
    "        \n",
    "    def forward_wo_optimize_parameters(self):\n",
    "        \"\"\"Calculate losses in validation set, run within torch.no_grad()\"\"\"\n",
    "        # forward\n",
    "        self.forward(val=True)\n",
    "        self.backward_G(val=True)\n",
    "        self.backward_D(val=True) \n",
    "        \n",
    "    def save_networks(self, epoch):\n",
    "        \"\"\"Save all the networks to the disk.\n",
    "        Parameters:\n",
    "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "        \"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                save_path = os.path.join(self.save_dir, save_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "\n",
    "                if isinstance(net, torch.nn.DataParallel):\n",
    "                    torch.save(net.module.state_dict(), save_path)\n",
    "                else:\n",
    "                    torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    def load_networks(self, epoch):\n",
    "        \"\"\"Load all the networks from the disk.\n",
    "        Parameters:\n",
    "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "        \"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                load_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                load_path = os.path.join(self.save_dir, load_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "                if isinstance(net, torch.nn.DataParallel):\n",
    "                    net = net.module\n",
    "                print('loading the model from %s' % load_path)\n",
    "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "                # GitHub source), you can remove str() on self.device\n",
    "                state_dict = torch.load(load_path, map_location=str(self.device))\n",
    "                if hasattr(state_dict, '_metadata'):\n",
    "                    del state_dict._metadata\n",
    "\n",
    "                # patch InstanceNorm checkpoints prior to 0.4\n",
    "                # for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
    "                #     self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
    "                net.load_state_dict(state_dict, strict=False)\n",
    "                \n",
    "    def update_learning_rate(self):\n",
    "        \"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"\n",
    "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate %.7f -> %.7f' % (old_lr, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model from ./models/deconv-GAN-512-40X-4/599_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "# Create model dir\n",
    "model_dir = \"./models/deconv-GAN-512-40X-4\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "model = DeconvGAN(is_train=False, device=torch.device(\"cuda:0\"), save_dir=model_dir, weight=[200, 1, 10, 0, 0.1, 0.2, 0.2])\n",
    "\n",
    "# Load model\n",
    "model.load_networks(599)  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stain_OD_norm_gt(df, image_name, bg=(0.754000, 0.077000, 0.652000)):\n",
    "    OD_h = df.loc[df['image name'] == image_name, (\"hR\", \"hG\", \"hB\")].values\n",
    "    OD_e = df.loc[df['image name'] == image_name, (\"eR\", \"eG\", \"eB\")].values\n",
    "    OD_h = -np.log(OD_h / 255 + 0.0001)\n",
    "    OD_h = (OD_h.T/np.linalg.norm(OD_h, axis=1).T).T\n",
    "    OD_h = np.mean(OD_h, axis=0)\n",
    "    OD_h /= np.linalg.norm(OD_h)\n",
    "    OD_e = -np.log(OD_e / 255 + 0.0001)\n",
    "    OD_e = (OD_e.T/np.linalg.norm(OD_e, axis=1).T).T\n",
    "    OD_e = np.mean(OD_e, axis=0)\n",
    "    OD_e /= np.linalg.norm(OD_e)\n",
    "    OD_norm = np.asarray((OD_h, OD_e, bg))\n",
    "    return torch.tensor(OD_norm)\n",
    "\n",
    "def preprocess(image, image_size):\n",
    "    if image.size()[2] < image_size:\n",
    "        image_temp = torch.zeros(image.size()[0], image.size()[1], image_size, image_size)\n",
    "        start = int((image_size - image.size()[2])/2)\n",
    "        image_temp[:, :, start:start + image.size()[2], start:start + image.size()[2]] = image\n",
    "        image = image_temp.contiguous()\n",
    "    return image\n",
    "\n",
    "def postprocess(image, origin_size):\n",
    "    if image.size()[2] > origin_size:\n",
    "        start = -int((origin_size - image.size()[2])/2)\n",
    "        image_temp = image[:, :, start:start + origin_size, start:start + origin_size]\n",
    "        image = image_temp.contiguous()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stain_OD_norm for HE deconv\n",
    "stain_OD_deconv = [[0.644211, 0.716556, 0.266844],  # Hematoxylin\n",
    "                   [0.092789, 0.964111, 0.283111],  # Eosin\n",
    "                   [0.754000, 0.077000, 0.652000]  # Bg\n",
    "                  ]\n",
    "stain_OD_norm_deconv = []\n",
    "for r in stain_OD_deconv:\n",
    "    stain_OD_norm_deconv.append(r/np.linalg.norm(r))\n",
    "stain_OD_norm_deconv = torch.tensor(np.asarray(stain_OD_norm_deconv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image name</th>\n",
       "      <th>hR</th>\n",
       "      <th>hG</th>\n",
       "      <th>hB</th>\n",
       "      <th>eR</th>\n",
       "      <th>eG</th>\n",
       "      <th>eB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10878_2_10.png</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>110</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10878_2_10.png</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>54</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10878_2_10.png</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>189</td>\n",
       "      <td>113</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10878_2_10.png</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>225</td>\n",
       "      <td>116</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10878_2_10.png</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>220</td>\n",
       "      <td>124</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10878_2_8.png</td>\n",
       "      <td>72</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>249</td>\n",
       "      <td>131</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10878_2_8.png</td>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>80</td>\n",
       "      <td>251</td>\n",
       "      <td>112</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10878_2_8.png</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>59</td>\n",
       "      <td>219</td>\n",
       "      <td>137</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10878_2_8.png</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "      <td>75</td>\n",
       "      <td>168</td>\n",
       "      <td>61</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10878_2_8.png</td>\n",
       "      <td>78</td>\n",
       "      <td>36</td>\n",
       "      <td>99</td>\n",
       "      <td>226</td>\n",
       "      <td>115</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10878_2_9.png</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>95</td>\n",
       "      <td>250</td>\n",
       "      <td>154</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10878_2_9.png</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>199</td>\n",
       "      <td>107</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10878_2_9.png</td>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>112</td>\n",
       "      <td>208</td>\n",
       "      <td>98</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10878_2_9.png</td>\n",
       "      <td>71</td>\n",
       "      <td>37</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10878_2_9.png</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>164</td>\n",
       "      <td>67</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11460_1_10.png</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>218</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11460_1_10.png</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>227</td>\n",
       "      <td>153</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11460_1_10.png</td>\n",
       "      <td>96</td>\n",
       "      <td>53</td>\n",
       "      <td>91</td>\n",
       "      <td>204</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11460_1_10.png</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "      <td>217</td>\n",
       "      <td>132</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11460_1_10.png</td>\n",
       "      <td>71</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "      <td>218</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11460_1_2.png</td>\n",
       "      <td>91</td>\n",
       "      <td>63</td>\n",
       "      <td>105</td>\n",
       "      <td>224</td>\n",
       "      <td>161</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11460_1_2.png</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>116</td>\n",
       "      <td>227</td>\n",
       "      <td>166</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11460_1_2.png</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>87</td>\n",
       "      <td>224</td>\n",
       "      <td>162</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11460_1_2.png</td>\n",
       "      <td>84</td>\n",
       "      <td>44</td>\n",
       "      <td>85</td>\n",
       "      <td>206</td>\n",
       "      <td>133</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11460_1_2.png</td>\n",
       "      <td>116</td>\n",
       "      <td>61</td>\n",
       "      <td>111</td>\n",
       "      <td>252</td>\n",
       "      <td>206</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11460_1_3.png</td>\n",
       "      <td>59</td>\n",
       "      <td>28</td>\n",
       "      <td>66</td>\n",
       "      <td>229</td>\n",
       "      <td>140</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11460_1_3.png</td>\n",
       "      <td>121</td>\n",
       "      <td>77</td>\n",
       "      <td>127</td>\n",
       "      <td>232</td>\n",
       "      <td>172</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11460_1_3.png</td>\n",
       "      <td>103</td>\n",
       "      <td>59</td>\n",
       "      <td>106</td>\n",
       "      <td>210</td>\n",
       "      <td>143</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11460_1_3.png</td>\n",
       "      <td>111</td>\n",
       "      <td>73</td>\n",
       "      <td>112</td>\n",
       "      <td>235</td>\n",
       "      <td>164</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11460_1_3.png</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>74</td>\n",
       "      <td>239</td>\n",
       "      <td>188</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NLSI0000078_2_10.png</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>147</td>\n",
       "      <td>159</td>\n",
       "      <td>133</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NLSI0000078_2_10.png</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>140</td>\n",
       "      <td>142</td>\n",
       "      <td>127</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NLSI0000078_2_10.png</td>\n",
       "      <td>130</td>\n",
       "      <td>124</td>\n",
       "      <td>162</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NLSI0000078_2_10.png</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>165</td>\n",
       "      <td>144</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>NLSI0000078_2_10.png</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>116</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NLSI0000078_2_6.png</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>133</td>\n",
       "      <td>176</td>\n",
       "      <td>163</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>NLSI0000078_2_6.png</td>\n",
       "      <td>108</td>\n",
       "      <td>97</td>\n",
       "      <td>146</td>\n",
       "      <td>184</td>\n",
       "      <td>168</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>NLSI0000078_2_6.png</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>146</td>\n",
       "      <td>154</td>\n",
       "      <td>133</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NLSI0000078_2_6.png</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>119</td>\n",
       "      <td>157</td>\n",
       "      <td>128</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NLSI0000078_2_6.png</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>197</td>\n",
       "      <td>163</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NLSI0000078_2_7.png</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>131</td>\n",
       "      <td>165</td>\n",
       "      <td>147</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NLSI0000078_2_7.png</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>139</td>\n",
       "      <td>164</td>\n",
       "      <td>139</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>NLSI0000078_2_7.png</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>130</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NLSI0000078_2_7.png</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>131</td>\n",
       "      <td>162</td>\n",
       "      <td>140</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>NLSI0000078_2_7.png</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>175</td>\n",
       "      <td>151</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NLSI0000078_2_8.png</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>127</td>\n",
       "      <td>149</td>\n",
       "      <td>132</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NLSI0000078_2_8.png</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>150</td>\n",
       "      <td>128</td>\n",
       "      <td>98</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NLSI0000078_2_8.png</td>\n",
       "      <td>104</td>\n",
       "      <td>99</td>\n",
       "      <td>141</td>\n",
       "      <td>152</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NLSI0000078_2_8.png</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>167</td>\n",
       "      <td>146</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NLSI0000078_2_8.png</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>95</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NLSI0000078_2_9.png</td>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>178</td>\n",
       "      <td>145</td>\n",
       "      <td>110</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NLSI0000078_2_9.png</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>156</td>\n",
       "      <td>131</td>\n",
       "      <td>106</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NLSI0000078_2_9.png</td>\n",
       "      <td>104</td>\n",
       "      <td>101</td>\n",
       "      <td>149</td>\n",
       "      <td>131</td>\n",
       "      <td>96</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NLSI0000078_2_9.png</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>144</td>\n",
       "      <td>157</td>\n",
       "      <td>134</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NLSI0000078_2_9.png</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>159</td>\n",
       "      <td>133</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NLSI0000165_1_1.png</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>100</td>\n",
       "      <td>157</td>\n",
       "      <td>92</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NLSI0000165_1_1.png</td>\n",
       "      <td>115</td>\n",
       "      <td>105</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>NLSI0000165_1_1.png</td>\n",
       "      <td>114</td>\n",
       "      <td>106</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>84</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NLSI0000165_1_1.png</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>167</td>\n",
       "      <td>91</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NLSI0000165_1_1.png</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>116</td>\n",
       "      <td>173</td>\n",
       "      <td>113</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image name   hR   hG   hB   eR   eG   eB\n",
       "0          10878_2_10.png   31   11   41  110   42   75\n",
       "1          10878_2_10.png   31   14   19  137   54   91\n",
       "2          10878_2_10.png   22   10   38  189  113  143\n",
       "3          10878_2_10.png   30    8   35  225  116  143\n",
       "4          10878_2_10.png   17   12   42  220  124  163\n",
       "5           10878_2_8.png   72   33   89  249  131  170\n",
       "6           10878_2_8.png   83   29   80  251  112  141\n",
       "7           10878_2_8.png   34   20   59  219  137  158\n",
       "8           10878_2_8.png   65   27   75  168   61  112\n",
       "9           10878_2_8.png   78   36   99  226  115  150\n",
       "10          10878_2_9.png   75   39   95  250  154  182\n",
       "11          10878_2_9.png   35   15   46  199  107  145\n",
       "12          10878_2_9.png   89   54  112  208   98  127\n",
       "13          10878_2_9.png   71   37   88  181   88  121\n",
       "14          10878_2_9.png   66   28   87  164   67   96\n",
       "15         11460_1_10.png   60   26   71  218  138  148\n",
       "16         11460_1_10.png   57   27   67  227  153  189\n",
       "17         11460_1_10.png   96   53   91  204  151  152\n",
       "18         11460_1_10.png   51   36   84  217  132  155\n",
       "19         11460_1_10.png   71   44   90  218  126  130\n",
       "20          11460_1_2.png   91   63  105  224  161  176\n",
       "21          11460_1_2.png  100   65  116  227  166  192\n",
       "22          11460_1_2.png   53   31   87  224  162  183\n",
       "23          11460_1_2.png   84   44   85  206  133  170\n",
       "24          11460_1_2.png  116   61  111  252  206  216\n",
       "25          11460_1_3.png   59   28   66  229  140  169\n",
       "26          11460_1_3.png  121   77  127  232  172  193\n",
       "27          11460_1_3.png  103   59  106  210  143  167\n",
       "28          11460_1_3.png  111   73  112  235  164  188\n",
       "29          11460_1_3.png   50   28   74  239  188  209\n",
       "..                    ...  ...  ...  ...  ...  ...  ...\n",
       "130  NLSI0000078_2_10.png  102  103  147  159  133  169\n",
       "131  NLSI0000078_2_10.png   95   93  140  142  127  160\n",
       "132  NLSI0000078_2_10.png  130  124  162  117   93  128\n",
       "133  NLSI0000078_2_10.png   81   80  130  165  144  175\n",
       "134  NLSI0000078_2_10.png   89   88  140  139  116  155\n",
       "135   NLSI0000078_2_6.png   98   91  133  176  163  190\n",
       "136   NLSI0000078_2_6.png  108   97  146  184  168  196\n",
       "137   NLSI0000078_2_6.png   96   94  146  154  133  168\n",
       "138   NLSI0000078_2_6.png   68   68  119  157  128  160\n",
       "139   NLSI0000078_2_6.png   57   53   96  197  163  190\n",
       "140   NLSI0000078_2_7.png   89   82  131  165  147  177\n",
       "141   NLSI0000078_2_7.png   90   80  139  164  139  174\n",
       "142   NLSI0000078_2_7.png   73   73  124  155  130  163\n",
       "143   NLSI0000078_2_7.png   81   84  131  162  140  172\n",
       "144   NLSI0000078_2_7.png   82   80  130  175  151  185\n",
       "145   NLSI0000078_2_8.png   77   77  127  149  132  163\n",
       "146   NLSI0000078_2_8.png  103  102  150  128   98  135\n",
       "147   NLSI0000078_2_8.png  104   99  141  152  132  164\n",
       "148   NLSI0000078_2_8.png   81   82  144  167  146  176\n",
       "149   NLSI0000078_2_8.png   71   72  121  120   95  129\n",
       "150   NLSI0000078_2_9.png  138  139  178  145  110  153\n",
       "151   NLSI0000078_2_9.png  111  108  156  131  106  144\n",
       "152   NLSI0000078_2_9.png  104  101  149  131   96  124\n",
       "153   NLSI0000078_2_9.png   94   95  144  157  134  160\n",
       "154   NLSI0000078_2_9.png   67   70  111  159  133  167\n",
       "155   NLSI0000165_1_1.png   60   44  100  157   92  124\n",
       "156   NLSI0000165_1_1.png  115  105  150  168  106  128\n",
       "157   NLSI0000165_1_1.png  114  106  142  153   84  116\n",
       "158   NLSI0000165_1_1.png   60   56   98  167   91  122\n",
       "159   NLSI0000165_1_1.png   81   67  116  173  113  144\n",
       "\n",
       "[160 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = Dataset(he_indexes_test, ihc_h_indexes_test, image_dict, augmentation=False, crop_size=IMAGE_SHAPE, \n",
    "                  crop_position=\"center\")\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=10)\n",
    "\n",
    "stain_OD_gt_df = pd.read_csv(\"../data/he_color_sampler_eosin.csv\")\n",
    "stain_OD_gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.netG.eval()\n",
    "device = model.device\n",
    "\n",
    "pred_OD_matrixs = []\n",
    "gt_OD_matrixs = []\n",
    "pred_ODs = []\n",
    "gt_ODs = []\n",
    "\n",
    "\n",
    "for idx, (images, _, _) in enumerate(test_loader):\n",
    "    # if idx % 5 != 0:\n",
    "    #     continue\n",
    "    print(idx)\n",
    "    image_name = he_indexes_test[idx]\n",
    "    batch_size = images.size(0)\n",
    "    origin_size = images.size(2)\n",
    "    images_norm = preprocess(images, IMAGE_SHAPE).float().to(device)\n",
    "    \n",
    "    # =================== forward =====================\n",
    "    with torch.no_grad():\n",
    "        ODs, stain_OD_norm_pred, params_lt = model.netG(images_norm)\n",
    "        ODs = postprocess(ODs.cpu(), origin_size).to(device)\n",
    "        # Linear transformation\n",
    "        # ODs[:, 0:1, ...] = ODs[:, 0:1, ...] * params_lt[:, 0, None, None, None] + params_lt[:, 1, None, None, None]\n",
    "        # Add rgb to ODs\n",
    "        rgb_ODs = torch.stack([torch.tensor([[0, 0.70711, 0.70711], \n",
    "                                             [0.70711, 0, 0.70711], \n",
    "                                             [0.70711, 0.70711, 0]]) for _ in range(ODs.size()[0])], 0)\n",
    "        stain_OD_norm_pred = torch.cat([stain_OD_norm_pred, rgb_ODs.to(device)], 1)\n",
    "    print(stain_OD_norm_pred)\n",
    "    print(params_lt)\n",
    "    recon_images = reconstruct(ODs[:, 0:2, ...], stain_OD_norm_pred[:, 0:2, ...], device)\n",
    "    recon_images_h = reconstruct(ODs[:, 0:1, ...], stain_OD_norm_pred[:, 0:1, ...], device)\n",
    "    recon_images_e = reconstruct(ODs[:, 1:2, ...], stain_OD_norm_pred[:, 1:2, ...], device)\n",
    "    recon_images_b = reconstruct(ODs[:, 2:6, ...], stain_OD_norm_pred[:, 2:6, ...], device)\n",
    "\n",
    "    ori_image = np.transpose(np.array(images.detach().cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0]\n",
    "    # _, ch1, ch2, ch3 = channel_deconvolution(ori_image, \"HEB\", to_normalize=False)\n",
    "    stain_OD_norm_deconv = get_stain_OD_norm_gt(stain_OD_gt_df, image_name, bg=(0.754000, 0.077000, 0.652000))\n",
    "    print(stain_OD_norm_deconv)\n",
    "    _, ch1, ch2, ch3 = channel_deconvolution(ori_image, \"costom\", to_normalize=False, \n",
    "                                             channels=(\"H\", \"E\", \"B\"), \n",
    "                                             stain_OD=stain_OD_norm_deconv.numpy())\n",
    "    _temp = np.array([[ch1, ch2, ch3]])\n",
    "    recon_images_deconv = reconstruct(_temp[:, 0:2, ...], stain_OD_norm_deconv[0:2], device)\n",
    "    recon_images_deconv_h = reconstruct(_temp[:, 0:1, ...], stain_OD_norm_deconv[0:1], device)\n",
    "    recon_images_deconv_e = reconstruct(_temp[:, 1:2, ...], stain_OD_norm_deconv[1:2], device)\n",
    "    recon_images_deconv_b = reconstruct(_temp[:, 2:3, ...], stain_OD_norm_deconv[2:3], device)\n",
    "    \n",
    "    # Save res\n",
    "    pred_OD_matrixs.append(stain_OD_norm_pred)\n",
    "    gt_OD_matrixs.append(stain_OD_norm_deconv)\n",
    "    pred_ODs.append(ODs)\n",
    "    gt_ODs.append(_temp)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(np.transpose(np.array(images.cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(np.transpose(np.array(reconstruct(ODs, stain_OD_norm_pred, device).detach().cpu().numpy()*255, \n",
    "                                     dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Reconstructed Image (All)\")\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(np.transpose(np.array(reconstruct(ODs, stain_OD_norm, device).detach().cpu().numpy()*255, \n",
    "                                     dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Normalized Image\")\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(np.transpose(np.array(np.clip(reconstruct(torch.log(ODs[:, 0:1, ...] + 1) * params_lt[:, 0, None, None, None] + \\\n",
    "                                                           params_lt[:, 1, None, None, None], \n",
    "                                                [[0.644211, 0.716556, 0.266844]], device).detach().cpu().numpy()*255, 0, 255),\n",
    "                                                 # stain_OD_norm_deconv[0:1], device).detach().cpu().numpy()*255, 0, 255), \n",
    "                                     dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Fake IHC H channel\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(np.transpose(np.array(recon_images.detach().cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(np.transpose(np.array(recon_images_h.detach().cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Hematoxylin\")\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(np.transpose(np.array(recon_images_e.detach().cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Eosin\")\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(np.transpose(np.array(recon_images_b.detach().cpu().numpy()*255, dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Background\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(np.transpose(np.array(np.clip(recon_images_deconv.detach().cpu().numpy()*255, 0, 255), dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(np.transpose(np.array(np.clip(recon_images_deconv_h.detach().cpu().numpy()*255, 0, 255), dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Hematoxylin\")\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(np.transpose(np.array(np.clip(recon_images_deconv_e.detach().cpu().numpy()*255, 0, 255), dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Eosin\")\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(np.transpose(np.array(np.clip(recon_images_deconv_b.detach().cpu().numpy()*255, 0, 255), dtype=np.uint8), (0, 2, 3, 1))[0])\n",
    "    plt.title(\"Background\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Evaluate OD matrixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff from gt_H:  0.09577141035898014\n",
      "Diff from gt_E:  0.16712343980953934\n",
      "Average diff:  0.13144742508425974\n"
     ]
    }
   ],
   "source": [
    "diff_h = []\n",
    "diff_e = []\n",
    "diff_all = []\n",
    "for pred_OD_matrix, gt_OD_matrix in zip(pred_OD_matrixs, gt_OD_matrixs):\n",
    "    pred_OD_matrix = pred_OD_matrix[0, 0:3, :].cpu().numpy()\n",
    "    gt_OD_matrix = gt_OD_matrix.cpu().numpy()\n",
    "    diff_h.append(np.sqrt(np.sum((pred_OD_matrix[0] - gt_OD_matrix[0]) ** 2)))\n",
    "    diff_e.append(np.sqrt(np.sum((pred_OD_matrix[1] - gt_OD_matrix[1]) ** 2)))\n",
    "    diff_all.append((np.sqrt(np.sum((pred_OD_matrix[0] - gt_OD_matrix[0]) ** 2)) + \\\n",
    "                     np.sqrt(np.sum((pred_OD_matrix[1] - gt_OD_matrix[1]) ** 2)))/2)\n",
    "print(\"Diff from gt_H: \", np.average(diff_h))\n",
    "print(\"Diff from gt_E: \", np.average(diff_e))\n",
    "print(\"Average diff: \", np.average(diff_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE from gt_H:  0.05485562303672945\n",
      "SE from gt_E:  0.10296748601795869\n",
      "SE from gt_ave:  0.029543887562069413\n"
     ]
    }
   ],
   "source": [
    "print(\"SE from gt_H: \", np.std(diff_h, ddof=1))\n",
    "print(\"SE from gt_E: \", np.std(diff_e, ddof=1))\n",
    "print(\"SE from gt_ave: \", np.std(diff_all, ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Evaluate nuclei signal-gt correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/swan15/.conda/envs/mask_rcnn_2/lib/python3.6/site-packages/ipykernel/__main__.py:15: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create and save gt mask\n",
    "'''\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes\n",
    "from scipy import misc\n",
    "for i in range(len(gt_ODs)):\n",
    "    image_name = he_indexes_test[i]\n",
    "    OD_h = gt_ODs[i][0, 0, ...]\n",
    "    OD_h = OD_h > threshold_otsu(OD_h)\n",
    "    OD_h = remove_small_objects(OD_h, 100)\n",
    "    OD_h = remove_small_holes(OD_h, 20)\n",
    "    OD_h_c = np.zeros((OD_h.shape[0], OD_h.shape[1], 4), dtype=np.uint8)\n",
    "    OD_h_c[..., 1] = OD_h * 255\n",
    "    OD_h_c[..., 3] = OD_h * 255\n",
    "    misc.imsave(os.path.join(\"../data/he_test_nuclei_mask/\", image_name), OD_h_c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "auc_scores = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "nuclei_gts = []\n",
    "OD_hs = []\n",
    "\n",
    "for i in range(len(he_indexes_test)):\n",
    "    image_name = he_indexes_test[i]\n",
    "    nuclei_gt = rgba2rgb(skimage.io.imread(os.path.join(\"../data/he_test_nuclei_mask/\", image_name)))[..., 1] ==255\n",
    "    nuclei_gt = nuclei_gt.astype(int).reshape(-1)\n",
    "    OD_h = pred_ODs[i].cpu().numpy()[0, 0, ...].reshape(-1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(nuclei_gt, OD_h)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    auc_scores.append(roc_auc_score(nuclei_gt, OD_h))\n",
    "    nuclei_gts.append(nuclei_gt)\n",
    "    OD_hs.append(OD_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664941324757357\n",
      "0.02126228538621625\n",
      "0.951839957671223\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.average(auc_scores))\n",
    "print(np.std(auc_scores, ddof=1))\n",
    "print(roc_auc_score(np.concatenate(nuclei_gts).reshape(-1), np.concatenate(OD_hs).reshape(-1)))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(len(he_indexes_test)):\n",
    "    if i == 0:\n",
    "        plt.plot(fprs[i], tprs[i], color='orange', alpha=0.4, label='Individual image patch')\n",
    "    else:\n",
    "        plt.plot(fprs[i], tprs[i], color='orange', alpha=0.4)\n",
    "fpr, tpr, thresholds = roc_curve(np.concatenate(nuclei_gts).reshape(-1), np.concatenate(OD_hs).reshape(-1))\n",
    "plt.plot(fpr, tpr, color='blue', label='Overall')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()\n",
    "\n",
    "torch.save([fpr, tpr], \"../outputs/2_roc_curve_evaluate_deconv_GAN_512_40X_4.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.7.0\r\n",
      "altair==3.2.0\r\n",
      "argh==0.26.2\r\n",
      "astor==0.7.1\r\n",
      "astropy==3.2.1\r\n",
      "atomicwrites==1.3.0\r\n",
      "attrs==19.1.0\r\n",
      "autograd==1.2\r\n",
      "backcall==0.1.0\r\n",
      "base58==1.0.3\r\n",
      "bleach==1.5.0\r\n",
      "blinker==1.4\r\n",
      "boto3==1.10.15\r\n",
      "botocore==1.13.15\r\n",
      "Bottleneck==1.2.1\r\n",
      "cachetools==4.1.0\r\n",
      "certifi==2019.3.9\r\n",
      "chardet==3.0.4\r\n",
      "Click==7.0\r\n",
      "cvxopt==1.2.3\r\n",
      "cvxpy==1.0.24\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.29.15\r\n",
      "decorator==4.4.0\r\n",
      "defusedxml==0.5.0\r\n",
      "dill==0.2.9\r\n",
      "docutils==0.15.2\r\n",
      "ecos==2.0.7.post1\r\n",
      "entrypoints==0.3\r\n",
      "enum-compat==0.0.3\r\n",
      "environment-kernels==1.1.1\r\n",
      "FITS-tools==0.2\r\n",
      "future==0.17.1\r\n",
      "gast==0.2.2\r\n",
      "google-auth==1.14.3\r\n",
      "google-auth-oauthlib==0.4.1\r\n",
      "google-pasta==0.2.0\r\n",
      "grpcio==1.29.0\r\n",
      "h5py==2.10.0\r\n",
      "html5lib==0.9999999\r\n",
      "idna==2.8\r\n",
      "image-registration==0.2.4\r\n",
      "imageio==2.6.1\r\n",
      "importlib-metadata==0.23\r\n",
      "ipykernel==5.1.0\r\n",
      "ipython==7.4.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.4.2\r\n",
      "isodate==0.6.0\r\n",
      "jedi==0.13.3\r\n",
      "Jinja2==2.10.1\r\n",
      "jmespath==0.9.4\r\n",
      "jsonschema==3.0.1\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==5.2.4\r\n",
      "jupyter-console==6.0.0\r\n",
      "jupyter-core==4.4.0\r\n",
      "Keras==2.3.1\r\n",
      "Keras-Applications==1.0.8\r\n",
      "Keras-Preprocessing==1.1.0\r\n",
      "kiwisolver==1.0.1\r\n",
      "lifelines==0.21.3\r\n",
      "lightgbm==2.3.1\r\n",
      "Markdown==3.0.1\r\n",
      "MarkupSafe==1.1.1\r\n",
      "matplotlib==3.0.3\r\n",
      "mistune==0.8.4\r\n",
      "mkl-fft==1.0.10\r\n",
      "mkl-random==1.0.2\r\n",
      "mock==2.0.0\r\n",
      "more-itertools==7.2.0\r\n",
      "mttkinter==0.6.1\r\n",
      "multiprocess==0.70.7\r\n",
      "nbconvert==5.4.1\r\n",
      "nbformat==4.4.0\r\n",
      "networkx==2.2\r\n",
      "notebook==5.7.8\r\n",
      "numexpr==2.6.9\r\n",
      "numpy==1.17.2\r\n",
      "oauthlib==3.1.0\r\n",
      "opencv-python==3.2.0.7\r\n",
      "openslide-python==1.1.1\r\n",
      "osqp==0.5.0\r\n",
      "packaging==19.2\r\n",
      "pandas==0.23.4\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.4.0\r\n",
      "pathtools==0.1.2\r\n",
      "patsy==0.5.1\r\n",
      "pbr==5.1.3\r\n",
      "pexpect==4.7.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==6.2.1\r\n",
      "pluggy==0.13.0\r\n",
      "plyfile==0.7\r\n",
      "pma-python==2.0.0.118\r\n",
      "prometheus-client==0.6.0\r\n",
      "prompt-toolkit==2.0.9\r\n",
      "protobuf==3.6.1\r\n",
      "ptyprocess==0.6.0\r\n",
      "py==1.8.0\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycocotools==2.0.0\r\n",
      "pydicom==1.4.2\r\n",
      "Pygments==2.3.1\r\n",
      "pyparsing==2.4.0\r\n",
      "pyrsistent==0.14.11\r\n",
      "pytest==5.1.2\r\n",
      "python-dateutil==2.8.0\r\n",
      "pytz==2018.9\r\n",
      "PyWavelets==1.0.2\r\n",
      "PyYAML==5.1.2\r\n",
      "pyzmq==18.0.1\r\n",
      "qtconsole==4.4.3\r\n",
      "rdflib==4.2.2\r\n",
      "requests==2.22.0\r\n",
      "requests-oauthlib==1.3.0\r\n",
      "requests-toolbelt==0.9.1\r\n",
      "rsa==4.0\r\n",
      "s3transfer==0.2.1\r\n",
      "scikit-image==0.15.0\r\n",
      "scikit-learn==0.20.3\r\n",
      "scikit-survival==0.8\r\n",
      "scipy==1.2.1\r\n",
      "scs==2.1.0\r\n",
      "seaborn==0.9.0\r\n",
      "Send2Trash==1.5.0\r\n",
      "Shapely==1.7.0\r\n",
      "simplejson==3.16.0\r\n",
      "six==1.12.0\r\n",
      "statsmodels==0.10.1\r\n",
      "streamlit==0.50.2\r\n",
      "tensorboard==1.14.0\r\n",
      "tensorflow==1.14.0\r\n",
      "tensorflow-estimator==1.14.0\r\n",
      "termcolor==1.1.0\r\n",
      "terminado==0.8.2\r\n",
      "testpath==0.4.2\r\n",
      "toml==0.10.0\r\n",
      "toolz==0.10.0\r\n",
      "torch==1.4.0\r\n",
      "torch-cluster==1.2.4\r\n",
      "torch-geometric==1.0.3\r\n",
      "torch-scatter==1.1.2\r\n",
      "torch-sparse==0.2.4\r\n",
      "torch-vision==0.1.6.dev0\r\n",
      "torchvision==0.5.0\r\n",
      "tornado==5.1.1\r\n",
      "tqdm==4.36.1\r\n",
      "traitlets==4.3.2\r\n",
      "tzlocal==2.0.0\r\n",
      "urllib3==1.25.7\r\n",
      "validators==0.14.0\r\n",
      "watchdog==0.9.0\r\n",
      "wcwidth==0.1.7\r\n",
      "webencodings==0.5.1\r\n",
      "Werkzeug==0.14.1\r\n",
      "widgetsnbextension==3.4.2\r\n",
      "wrapt==1.12.1\r\n",
      "xgboost==1.0.2\r\n",
      "zipp==0.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mask_rcnn_2)",
   "language": "python",
   "name": "conda_mask_rcnn_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
